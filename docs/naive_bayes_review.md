# 스팸 필터링 모델 검토: 나이브 베이즈의 한계와 대안 모델

## 개요

본 문서는 기업 메시징 중계 서버 스팸 필터 시스템에 적용할 머신러닝 모델에 대한 검토 결과를 제시합니다. 초기에 검토한 나이브 베이즈(Naive Bayes) 모델의 한계점을 분석하고, 더 높은 스팸 판독률을 제공할 수 있는 대안 모델들을 비교 평가합니다.

## 목차
1. [나이브 베이즈 모델 평가](#1-나이브-베이즈-모델-평가)
2. [대안 모델 검토](#2-대안-모델-검토)
3. [시스템 요구사항 부합성 비교](#3-시스템-요구사항-부합성-비교)
4. [권장 모델 및 구현 방안](#4-권장-모델-및-구현-방안)
5. [도입 고려사항](#5-도입-고려사항)
6. [비용 대비 효과 분석](#6-비용-대비-효과-분석)
7. [결론 및 권장사항](#7-결론-및-권장사항)

## 1. 나이브 베이즈 모델 평가

### 1.1 나이브 베이즈 모델 개요
나이브 베이즈 모델은 베이즈 정리(Bayes' theorem)를 기반으로 하며, 특성들 간의 독립성(naive independence)을 가정하는 확률적 분류 알고리즘입니다. 스팸 필터링에서 오랫동안 사용되어 왔으나, 최근 더 복잡한 스팸 패턴에 대응하는 데 한계를 보이고 있습니다.

### 1.2 나이브 베이즈의 한계점

#### 1.2.1 낮은 스팸 판독률
최근 성능 평가 결과, 나이브 베이즈 모델은 다음과 같은 한계로 인해 기대했던 스팸 판독률에 미치지 못하는 것으로 확인되었습니다:

- **정확도 한계**: 최신 스팸 데이터셋에서 75-80% 수준의 정확도로, 요구되는 95% 이상의 정확도에 미달
- **특성 독립성 가정의 한계**: 단어 간 관계를 고려하지 못해 문맥 기반 스팸 탐지에 취약
- **복잡한 패턴 인식 부족**: 교묘한 스팸 기법(단어 변형, 이미지 링크 등)에 대응 능력 부족
- **오탐률(False Positive) 증가**: 정상 메시지를 스팸으로 잘못 분류하는 비율이 허용 기준 초과

#### 1.2.2 장단점 분석
**장점**:
- 계산 효율성 및 빠른 처리 속도
- 적은 훈련 데이터로도 구현 가능
- 구현 및 유지보수 용이성

**단점**:
- 낮은 스팸 판독률 (주요 문제점)
- 특성 간 독립성 가정으로 인한 정확도 제한
- 복잡한 패턴 및 문맥 이해 부족
- 새로운 유형의 스팸에 대한 적응력 부족

## 2. 대안 모델 검토

### 2.1 랜덤 포레스트(Random Forest)

#### 2.1.1 모델 개요
랜덤 포레스트는 여러 결정 트리의 앙상블 기법으로, 다양한 특성 조합을 통해 높은 정확도와 과적합 방지 능력을 제공합니다.

#### 2.1.2 스팸 필터링 적용 시 장단점
**장점**:
- 높은 정확도 (88-93%)
- 특성 간 상호작용 고려 가능
- 과적합에 강한 내성
- 특성 중요도 평가 기능

**단점**:
- 나이브 베이즈보다 계산 비용 증가
- 메모리 사용량 증가
- 모델 크기가 상대적으로 큼

#### 2.1.3 성능 지표
- 정확도: 88-93%
- 처리 시간: 5-15ms (최적화 시)
- 메모리 사용량: 중간
- 오탐률: 5-8%

### 2.2 서포트 벡터 머신(SVM)

#### 2.2.1 모델 개요
SVM은 데이터 포인트를 고차원 공간에 매핑하여 최적의 결정 경계를 찾는 알고리즘으로, 텍스트 분류에서 높은 성능을 보입니다.

#### 2.2.2 스팸 필터링 적용 시 장단점
**장점**:
- 높은 정확도 (90-94%)
- 고차원 데이터에서도 효과적
- 다양한 커널 함수를 통한 유연성

**단점**:
- 대규모 데이터셋에서 학습 시간 증가
- 하이퍼파라미터 튜닝 복잡성
- 처리 시간이 나이브 베이즈보다 길 수 있음

#### 2.2.3 성능 지표
- 정확도: 90-94%
- 처리 시간: 8-20ms (최적화 시)
- 메모리 사용량: 중간
- 오탐률: 4-7%

### 2.3 그래디언트 부스팅(XGBoost/LightGBM)

#### 2.3.1 모델 개요
그래디언트 부스팅은 약한 학습기(주로 결정 트리)를 순차적으로 학습시켜 이전 모델의 오차를 보완하는 앙상블 기법입니다. XGBoost와 LightGBM은 최적화된 구현으로 높은 성능과 효율성을 제공합니다.

#### 2.3.2 스팸 필터링 적용 시 장단점
**장점**:
- 매우 높은 정확도 (92-96%)
- 특성 중요도 평가 기능
- 다양한 손실 함수 지원
- 효율적인 구현으로 빠른 학습 및 추론

**단점**:
- 하이퍼파라미터 튜닝 복잡성
- 랜덤 포레스트보다 과적합 위험 높음
- 모델 크기가 상대적으로 큼

#### 2.3.3 성능 지표
- 정확도: 92-96%
- 처리 시간: 3-12ms (최적화 시)
- 메모리 사용량: 중간
- 오탐률: 3-5%

### 2.4 딥러닝 모델(LSTM/Transformer)

#### 2.4.1 모델 개요
LSTM(Long Short-Term Memory)과 Transformer는 시퀀스 데이터 처리에 특화된 딥러닝 아키텍처로, 문맥 이해 능력이 뛰어납니다.

#### 2.4.2 스팸 필터링 적용 시 장단점
**장점**:
- 매우 높은 정확도 (94-98%)
- 뛰어난 문맥 이해 능력
- 복잡한 패턴 인식 가능
- 지속적 학습을 통한 성능 향상

**단점**:
- 높은 계산 비용
- 긴 처리 시간 (10ms 요구사항 충족 어려움)
- 대량의 훈련 데이터 필요
- 구현 및 유지보수 복잡성

#### 2.4.3 성능 지표
- 정확도: 94-98%
- 처리 시간: 30-100ms (최적화 필요)
- 메모리 사용량: 높음
- 오탐률: 2-4%

## 3. 시스템 요구사항 부합성 비교

### 3.1 성능 요구사항 부합성 비교

| 모델 | REQ-NF-001 (1000 TPS) | REQ-NF-002 (10ms 처리) | REQ-NF-003 (24시간 운영) | REQ-NF-004 (최대 부하) |
|------|----------------------|----------------------|------------------------|----------------------|
| 나이브 베이즈 | 매우 높음 | 매우 높음 | 높음 | 높음 |
| 랜덤 포레스트 | 높음 | 중간-높음 | 높음 | 중간-높음 |
| SVM | 중간-높음 | 중간 | 높음 | 중간 |
| XGBoost/LightGBM | 높음 | 높음 | 높음 | 높음 |
| 딥러닝(LSTM/Transformer) | 낮음 | 매우 낮음 | 중간 | 낮음 |

### 3.2 기능 요구사항 부합성 비교

| 모델 | REQ-F-001 (실시간 분석) | REQ-F-002 (머신러닝 기반) | REQ-F-006 (오탐/미탐 최소화) | REQ-F-007 (실시간 업데이트) |
|------|------------------------|------------------------|----------------------------|--------------------------|
| 나이브 베이즈 | 높음 | 중간 | 낮음 | 높음 |
| 랜덤 포레스트 | 중간-높음 | 높음 | 높음 | 중간 |
| SVM | 중간 | 높음 | 높음 | 낮음-중간 |
| XGBoost/LightGBM | 중간-높음 | 높음 | 매우 높음 | 중간 |
| 딥러닝(LSTM/Transformer) | 낮음 | 매우 높음 | 매우 높음 | 낮음 |

### 3.3 스팸 판독률 비교

| 모델 | 정확도 | 정밀도 | 재현율 | F1 점수 | 오탐률 |
|------|-------|-------|-------|---------|-------|
| 나이브 베이즈 | 75-80% | 78-83% | 70-75% | 74-79% | 15-20% |
| 랜덤 포레스트 | 88-93% | 90-94% | 85-90% | 87-92% | 5-8% |
| SVM | 90-94% | 92-95% | 88-92% | 90-93% | 4-7% |
| XGBoost/LightGBM | 92-96% | 94-97% | 90-94% | 92-95% | 3-5% |
| 딥러닝(LSTM/Transformer) | 94-98% | 95-98% | 93-97% | 94-97% | 2-4% |

## 4. 권장 모델 및 구현 방안

### 4.1 권장 모델: LightGBM
시스템 요구사항과 스팸 판독률을 종합적으로 고려할 때, **LightGBM**이 최적의 대안으로 평가됩니다:

- 높은 스팸 판독률 (92-96%)
- 10ms 이내 처리 시간 달성 가능 (최적화 시 3-12ms)
- 1000 TPS 처리 가능
- 낮은 오탐률 (3-5%)
- 효율적인 메모리 사용

### 4.2 구현 방식
```python
import lightgbm as lgb
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline

# 파이프라인 구성
spam_classifier = Pipeline([
    ('tfidf', TfidfVectorizer(
        max_features=10000,
        ngram_range=(1, 2),
        sublinear_tf=True
    )),
    ('clf', lgb.LGBMClassifier(
        n_estimators=100,
        num_leaves=31,
        learning_rate=0.05,
        objective='binary',
        metric='binary_logloss',
        boost_from_average=True,
        feature_fraction=0.8,
        bagging_fraction=0.8,
        bagging_freq=5
    ))
])

# 모델 학습
spam_classifier.fit(X_train, y_train)

# 스팸 확률 예측
spam_proba = spam_classifier.predict_proba(X_new)[:, 1]
```

### 4.3 성능 최적화 방안

#### 4.3.1 특성 엔지니어링
- TF-IDF 특성 최적화
- 중요 특성 선택 (Feature Selection)
- 도메인 특화 특성 추가 (URL 수, 특수문자 비율 등)
- 텍스트 전처리 파이프라인 최적화

#### 4.3.2 모델 최적화
- 하이퍼파라미터 튜닝
- 모델 경량화 (가지치기)
- 앙상블 크기와 복잡성 균형 조정
- 조기 종료(Early Stopping) 구현

#### 4.3.3 추론 최적화
- 모델 양자화
- 배치 처리 구현
- 병렬 처리 활용
- 추론 전용 라이브러리 사용 (ONNX Runtime)

## 5. 도입 고려사항

### 5.1 데이터 요구사항
- **초기 훈련 데이터**: 최소 50,000건 이상의 레이블된 메시지(스팸/정상) 필요
- **데이터 품질**: 다양한 스팸 유형을 포함한 균형 잡힌 데이터셋 구성
- **지속적 데이터 수집**: 새로운 스팸 패턴 학습을 위한 데이터 수집 체계 구축

### 5.2 개인정보 보호 및 법적 고려사항
- 훈련 데이터에서 개인식별정보(PII) 제거
- 데이터 수집 및 처리에 관한 법적 규제 준수
- 오탐으로 인한 정상 메시지 차단 시 법적 책임 고려

### 5.3 운영 고려사항
- 모델 버전 관리 및 롤백 메커니즘
- 정기적인 모델 재학습 일정 수립
- 성능 모니터링 및 알림 체계 구축
- 사용자 피드백 수집 및 반영 프로세스

## 6. 비용 대비 효과 분석

### 6.1 모델별 비용 대비 효과 비교

| 모델 | 개발 비용 | 운영 비용 | 유지보수 비용 | 정확도 | ROI |
|------|----------|----------|--------------|-------|-----|
| 나이브 베이즈 | 낮음 | 매우 낮음 | 낮음 | 낮음 | 중간 |
| 랜덤 포레스트 | 중간 | 중간 | 중간 | 높음 | 높음 |
| SVM | 중간 | 중간 | 중간-높음 | 높음 | 중간-높음 |
| LightGBM | 중간-높음 | 중간 | 중간 | 매우 높음 | 매우 높음 |
| 딥러닝(LSTM/Transformer) | 매우 높음 | 높음 | 높음 | 매우 높음 | 중간 |

### 6.2 LightGBM의 비용 대비 효과
- **개발 비용**: 중간-높음 (초기 구현 및 최적화에 투자 필요)
- **운영 비용**: 중간 (나이브 베이즈보다 높지만 합리적인 수준)
- **유지보수 비용**: 중간 (정기적인 모델 업데이트 및 모니터링 필요)
- **ROI**: 매우 높음 (높은 스팸 판독률로 인한 사용자 만족도 및 시스템 신뢰성 향상)

## 7. 결론 및 권장사항

### 7.1 결론
나이브 베이즈 모델은 낮은 스팸 판독률로 인해 시스템 요구사항을 충족하지 못하는 것으로 평가되었습니다. 대안 모델 중 LightGBM이 다음과 같은 이유로 가장 적합한 것으로 판단됩니다:

1. **높은 스팸 판독률**: 92-96%의 정확도로 나이브 베이즈(75-80%)보다 크게 향상
2. **성능 요구사항 충족**: 최적화 시 10ms 이내 처리 시간과 1000 TPS 처리량 요구사항 만족 가능
3. **낮은 오탐률**: 3-5%의 오탐률로 사용자 경험 향상
4. **적응성**: 새로운 스팸 패턴에 대한 높은 적응력
5. **비용 효율성**: 개발 및 운영 비용 대비 높은 성능 제공

### 7.2 권장사항
1. **LightGBM 모델 도입**: 높은 스팸 판독률과 성능 요구사항을 모두 충족하는 LightGBM 모델 채택
2. **하이브리드 접근법 유지**: LightGBM + 규칙 기반 필터 + 블랙리스트 조합으로 정확도 향상
3. **특성 엔지니어링 강화**: 도메인 특화 특성 및 고급 텍스트 특성 개발
4. **점진적 학습 체계 구축**: 사용자 피드백 기반 지속적 모델 업데이트 시스템 구현
5. **성능 모니터링 강화**: 정확도, 처리 시간, 리소스 사용량 등 주요 지표 지속적 모니터링

### 7.3 구현 로드맵
1. **1단계 (2-3주)**: LightGBM 모델 구현 및 초기 데이터셋 구축
2. **2단계 (3-4주)**: 특성 엔지니어링 및 모델 최적화
3. **3단계 (4-5주)**: 추론 최적화 및 성능 튜닝
4. **4단계 (5-7주)**: 하이브리드 시스템 통합 및 테스트
5. **5단계 (8-10주)**: 점진적 학습 및 피드백 시스템 구축
6. **6단계 (지속)**: 모니터링 및 지속적 개선

LightGBM 모델은 나이브 베이즈의 낮은 스팸 판독률 문제를 해결하면서도, 시스템의 핵심 요구사항인 빠른 처리 시간과 높은 처리량을 충족할 수 있는 최적의 대안으로 판단됩니다. 